# ######bash
sudo apt-get install fastqc  # for Ubuntu/Linux 
cd ~/Desktop/datam  # my fastq. datas for analysis


mkdir -p fastqc_reports  # create a file for fastqc reports
fastqc -o fastqc_reports *.fastq.gz  # analyze all of fastq files

pip install multiqc  # MultiQC is installed with the Python package manager

# MultiQC ile tüm FastQC raporlarını birleştir
multiqc fastqc_reports/ -o fastqc_reports_summary

# decision paramaters: 
# 1. Adapter Content: If adapter sequences are seen 5% or more, trimming is required.
# 2. Per Base Sequence Quality: Trimming can be performed if there are reads with a low quality score (usually Phred score < 20).
# 3. Per Sequence GC Content: If sequence quality and GC ratio are abnormally distributed, trimming may be required due to low quality reads.


# ####R
install.packages("fastqcr")

library(fastqcr)

# FastQC raporlarının bulunduğu dizin
qc_path <- "fastqc_reports"

# Tüm FastQC raporlarını birleştir
qc <- qc_aggregate(qc_path)

# FastQC sonuçlarının özetini görüntüle
qc_stats(qc)

# Adapter Content sorunu olan dosyaları listele
adapter_issues <- subset(qc, module == "Adapter Content" & status == "FAIL")
if (nrow(adapter_issues) > 0) {
    print("Need trimming. These files have adaptors:")
    print(adapter_issues$sample)
} else {
    print("There is no adaptor problem.")
}

# Check the overall quality status
quality_issues <- subset(qc, module == "Per base sequence quality" & status == "FAIL")
if (nrow(quality_issues) > 0) {
    print("There are low quality readings. Trim recommended.")
    print(quality_issues$sample)
} else {
    print("There is no adaptor problem.")
}



# ######back to bash
# for multidata trimming:
for r1 in /Users/Fastq_files/*_R1_*.fastq
do
    r2="${r1/_R1_/_R2_}"  # R2 dosyasının ismini otomatik oluşturur
    trim_galore --paired "$r1" "$r2" -o "/Users/merveyilmaz/Desktop/butun_belgeler/Acelya_Hocam/calismalar/Nanoplastic/Transkriptomic/Fastq_files/trimmed_fastqs"
done


brew install star
  # for Ubuntu/Linux 

STAR --version # check version and install

# Indexing the reference genome with STAR

mkdir -p star_index  # create a file for index files
STAR --runThreadN 8 --runMode genomeGenerate \
     --genomeDir star_index \
     --genomeFastaFiles path_to_reference/genome.fa \  # referance genome
     --sjdbGTFfile path_to_reference/annotations.gtf \  # referance annotations file
     --sjdbOverhang 100  # Adjust according to your read length (e.g. for 100bp paired-end)

mkdir -p star_output  # Hizalama sonuçları için bir klasör oluşturun
for sample in trimmed/*_val_1.fq.gz
do
    # Let's remove the base name from the file names
    base=$(basename ${sample} "_val_1.fq.gz")

####It is recommended to perform this analysis with access to Supercomputers. 

    STAR --runThreadN 8 \
         --genomeDir star_index \  # Önceden oluşturduğunuz indeks klasörü
         --readFilesIn trimmed/${base}_val_1.fq.gz trimmed/${base}_val_2.fq.gz \  # Trimlenmiş paired-end dosyalar
         --outFileNamePrefix star_output/${base}_ \  # Çıkış dosyalarının ön eki
         --outSAMtype BAM SortedByCoordinate \  # BAM formatında sıralı çıktı
         --readFilesCommand zcat  # Sıkıştırılmış dosyaları açmak için
done

#### now we are counting 

sudo apt-get install subread  # for Ubuntu/Linux 

mkdir -p counts  # create a file for counting results
featureCounts -T 8 -a path_to_reference/annotations.gtf \  # GTF file (genom anotasyonu)
              -o counts/gene_counts.txt star_output/*.bam  # all BAM files

### for Deseq2, back to R

if (!requireNamespace("BiocManager", quietly = TRUE)) install.packages("BiocManager")
BiocManager::install("DESeq2")

# Load necessary libraries
library(DESeq2)

# Load the gene count data generated by FeatureCounts
count_data <- read.table("counts/gene_counts.txt", header = TRUE, row.names = 1)

# Load metadata about the samples (make sure the file has 'sample' and 'condition' columns)
col_data <- read.csv("samples.csv", header = TRUE, row.names = 1)

# Prepare DESeq2 dataset object
dds <- DESeqDataSetFromMatrix(countData = count_data[, -1], colData = col_data, design = ~ condition)

# Run the differential expression analysis
dds <- DESeq(dds)

# Extract results for differentially expressed genes (default padj < 0.1)
res <- results(dds)

# Filter significant results (e.g., padj < 0.05 and log2FoldChange > 1)
res_filtered <- subset(res, padj < 0.05 & abs(log2FoldChange) > 1)

# View summary of the DE analysis
summary(res)

# Save the differential expression results to a CSV file
write.csv(as.data.frame(res_filtered), file = "differential_expression_results.csv")

# Plot MA-Plot
plotMA(res, ylim = c(-5, 5))

# Visualize significant genes with a volcano plot (log2FoldChange vs -log10(p-value))
library(ggplot2)
volcano_data <- data.frame(log2FC = res$log2FoldChange, pvalue = -log10(res$pvalue))
ggplot(volcano_data, aes(x = log2FC, y = pvalue)) +
  geom_point(alpha = 0.5) +
  theme_minimal() +
  ggtitle("Volcano Plot of Differential Expression")



#### Sample Metadata File (samples.csv) 

sample,condition
sample1,control
sample2,control
sample3,treated
sample4,treated











